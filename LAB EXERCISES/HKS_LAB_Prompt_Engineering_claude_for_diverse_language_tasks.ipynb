{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a9aa5d",
   "metadata": {},
   "source": [
    "# Demo 1 - Customizing Claude for Diverse Language Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ab3c4-df7b-46a6-be0c-a70a45b3067d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This lab focuses on demonstrating prompt engineering techniques using Anthropic's Claude. Prompt engineering is a critical aspect of utilizing Claude models effectively, as it involves crafting prompts that generate desired outputs. In this lab, we will cover various scenarios, including QnA, summarizing text, classifying text, generating new product names, translation, parsing unstructured data, and translating natural language queries into SQL queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160dc83-b832-470b-bbe5-0813e36636a5",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    " - Ensure you have an Anthropic API account.\n",
    " - Install the required libraries: `anthropic` and `python-dotenv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb96b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (0.57.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anthropic) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anthropic) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anthropic) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anthropic) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anthropic) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.25.0->anthropic) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install anthropic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d61902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79f5ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457eb2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anthropic version = 0.57.1\n"
     ]
    }
   ],
   "source": [
    "print(\"anthropic version =\", anthropic.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab12be4-515a-4d70-bf1b-fe5e9dbb4523",
   "metadata": {},
   "source": [
    "Set up your Anthropic API key. You can either set it as an environment variable or directly in the code (not recommended for production):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8242afa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Option 1: Set directly (replace with your actual API key)\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Option 2: Load from .env file (recommended)\n",
    "# Create a .env file with: ANTHROPIC_API_KEY=your-api-key-here\n",
    "# from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pJY3o96aIWca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Initialize the Anthropic client\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "# Choose your Claude model\n",
    "# Options: \"claude-3-7-sonnet-20250219\" (recommended), \"claude-sonnet-4-20250514\", \"claude-3-5-haiku-20241022\"\n",
    "model = \"claude-3-7-sonnet-20250219\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2b951b2-f2ae-4e63-bc88-83181587ccd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ac1fa",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a33a2",
   "metadata": {},
   "source": [
    "### 1. QnA\n",
    "In this section, we will use Claude to answer questions.\n",
    "\n",
    "The primary goal of this section is to showcase how the model can understand and generate meaningful responses based on the given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8V-pTJeXl22D",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I'm designed to engage in conversations, answer questions, assist with tasks like writing and analysis, and provide information on a wide range of topics. I have certain limitations - I don't have the ability to browse the internet, access files unless you upload them, or take actions outside our conversation. I aim to be balanced and thoughtful in my responses while prioritizing accuracy and helpfulness.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Who are you?\n",
    "\"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=150,\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448867c5-e9e7-4300-a55c-17545692192d",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "1.  **Prompt Definition:** The variable `prompt` contains the question provided to the model. In this case, the question is \"Who are you?\"\n",
    "    \n",
    "2.  **API Call:** The `client.messages.create` function is used to send a request to the Claude API. It takes parameters such as the model, max_tokens (maximum number of tokens in the response), and temperature.\n",
    "    \n",
    "3.  **Response Handling:** The API response is stored in the `response` variable, and the generated text is extracted from it using `response.content[0].text`.\n",
    "    \n",
    "4.  **Output Printing:** The final generated text is printed to the console.\n",
    "    \n",
    "\n",
    "### Purpose\n",
    "\n",
    "-   **Demonstrating Question Understanding:** This section serves to illustrate how Claude can comprehend and respond appropriately to a given question. The model attempts to provide a coherent answer based on its understanding of the input prompt.\n",
    "    \n",
    "-   **Interaction with the Model:** It showcases the basic interaction pattern with the Claude API for question and answer tasks, emphasizing the simplicity of the API integration for such scenarios.\n",
    "    \n",
    "-   **User-Specific Applications:** This functionality is valuable for a range of applications, including chatbots, virtual assistants, and information retrieval systems where users can pose questions, and the system generates relevant responses.\n",
    "    \n",
    "-   **Flexibility in Questioning:** The model's ability to handle various types of questions and provide contextually relevant answers highlights its versatility in natural language understanding.\n",
    "    \n",
    "    \n",
    "\n",
    "> ### Note\n",
    ">\n",
    "> Depending on the nature of the prompt and the desired application, additional parameters such as temperature (controls randomness in the model's output) and max_tokens (limits the length of the response) can be adjusted to fine-tune the behavior of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12c61ffe-6987-40db-bb7f-5426336c55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! It's nice to meet you.\n"
     ]
    }
   ],
   "source": [
    "  response = client.messages.create(                                            \n",
    "      model=\"claude-3-haiku-20240307\",                                          \n",
    "      max_tokens=50,                                                            \n",
    "      messages=[{\"role\": \"user\", \"content\": \"Say hi\"}]                          \n",
    "  )                                                                             \n",
    "  print(response.content[0].text)                                               \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb89a8de-f3c2-4f97-a5d6-3f5e58f201ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```yaml\n",
      "product:\n",
      "  name: iPhone 13\n",
      "  price: $799\n",
      "  availability: In stock\n",
      "  features:\n",
      "    - 5G\n",
      "    - OLED display\n",
      "    - A15 chip\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a YAML response for a product:\n",
    "- Product Name: iPhone 13\n",
    "- Price: $799\n",
    "- Availability: In stock\n",
    "- Features: 5G, OLED display, A15 chip\n",
    "\"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a70a9-5863-4650-a516-ed61df4e3496",
   "metadata": {},
   "source": [
    "Generate text in French based on a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd361b3c-e1b7-4288-a067-f16a637f42b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour! Comment puis-je vous aider aujourd'hui?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Bonjour\"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=100,\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ca234-4f05-461b-9b68-09ed8c78fc75",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "1.  **Prompt Definition:** The variable `prompt` contains a French greeting, \"Bonjour,\" which translates to \"Hello\" in English.\n",
    "    \n",
    "2.  **API Call:** The `client.messages.create` function is used to send a request to the Claude API. The parameters include:\n",
    "    \n",
    "    -   `model`: Specifies the Claude model to use.\n",
    "    -   `messages`: The input text provided to the model (`\"Bonjour\"` in French).\n",
    "    -   `temperature`: Controls the randomness of the model's output (set to `0.7` for balanced creativity).\n",
    "    -   `max_tokens`: Limits the length of the generated text.\n",
    "3.  **Response Handling:** The API response is stored in the `response` variable. The generated text is then extracted using `response.content[0].text`.\n",
    "    \n",
    "4.  **Output Printing:** The final generated text is printed to the console.\n",
    "    \n",
    "\n",
    "### Purpose\n",
    "\n",
    "-   **Language Translation:** This code snippet demonstrates the model's ability to understand and respond in French. It can be used for language translation tasks where the model takes input in one language and generates corresponding output in another language.\n",
    "    \n",
    "-   **Multilingual Capabilities:** Claude's multilingual capabilities allow it to handle prompts in various languages, showcasing its versatility in natural language understanding and generation.\n",
    "    \n",
    "-   **User Interface Localization:** In applications with multilingual user interfaces, this capability can be employed to dynamically generate responses in the user's preferred language.\n",
    "    \n",
    "\n",
    "> ### Note\n",
    ">\n",
    "> -   The choice of the `temperature` parameter influences the randomness of the model's responses. A lower temperature value (e.g., 0) produces more deterministic and focused output, while higher values introduce more randomness.\n",
    ">\n",
    "> -   Adjustments to the `max_tokens` parameter can be made based on the desired length of the generated text. Setting an appropriate value prevents overly long responses.\n",
    ">     \n",
    "> -   This code illustrates how Claude can seamlessly handle prompts in different languages, showcasing its potential in internationalization and localization contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399df257",
   "metadata": {},
   "source": [
    "### 2. Summarize Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60206f2a-d80c-4cf7-a573-a937469b860b",
   "metadata": {},
   "source": [
    "Model's ability to summarize a given text into three short bullet points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77a97dbc-8703-4d87-821a-348d2e47aadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neutron Star Summary\n",
      "\n",
      "• Neutron stars are collapsed cores of massive supergiant stars (10-25+ solar masses) formed after supernova explosions.\n",
      "\n",
      "• They are the smallest and densest stellar objects except for black holes and certain hypothetical objects, with a radius of about 10 km and mass of 1.4 solar masses.\n",
      "\n",
      "• They form through gravitational collapse that compresses the core beyond white dwarf density to that of atomic nuclei.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Summarize below text in 3 short bullet points：\n",
    "\n",
    "            ###\n",
    "            A neutron star is the collapsed core of a massive supergiant star,\n",
    "            which had a total mass of between 10 and 25 solar masses,\n",
    "            possibly more if the star was especially metal-rich.\n",
    "            Neutron stars are the smallest and densest stellar objects,\n",
    "            excluding black holes and hypothetical white holes, quark stars,\n",
    "            and strange stars. Neutron stars have a radius on the order of\n",
    "            10 kilometres (6.2 mi) and a mass of about 1.4 solar masses.\n",
    "            They result from the supernova explosion of a massive star,\n",
    "            combined with gravitational collapse, that compresses the core\n",
    "            past white dwarf star density to that of atomic nuclei.\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    system=\"You are an astronomer assistant.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24743ef3-5bd0-4e5a-894a-c56525661e83",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "1.  **Prompt Definition:**\n",
    "    \n",
    "    -   The variable `prompt` contains a lengthy text describing neutron stars. The prompt instructs the model to summarize this text into three short bullet points.\n",
    "2.  **API Call:**\n",
    "    \n",
    "    -   The `client.messages.create` function is used to send a request to the Claude API.\n",
    "    -   The `model` parameter specifies the Claude model to be used.\n",
    "    -   The `messages` parameter provides the input text (description of a neutron star) to the model.\n",
    "    -   The `temperature` parameter is set to 0.7, allowing for creative yet focused output.\n",
    "    -   The `max_tokens` parameter limits the length of the generated text to 800 tokens.\n",
    "    -   The `system` parameter sets the role/context for the assistant.\n",
    "3.  **Response Handling:**\n",
    "    \n",
    "    -   The API response, including the generated text, is stored in the `response` variable.\n",
    "4.  **Output Printing:**\n",
    "    \n",
    "    -   The generated summary text is extracted from the API response using `response.content[0].text`.\n",
    "    -   The final result is printed to the console.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "-   **Text Summarization:**\n",
    "    \n",
    "    -   The primary purpose is to showcase the model's ability to condense a longer piece of text into a concise summary, represented as three short bullet points.\n",
    "-   **Information Extraction:**\n",
    "    \n",
    "    -   It demonstrates how the model can extract key information from a given passage and present it in a structured format, which is particularly useful for distilling essential details from large bodies of text.\n",
    "-   **Automation of Summary Generation:**\n",
    "    \n",
    "    -   Developers can use this code as a foundation for automating the process of summarizing documents or articles, streamlining information extraction tasks.\n",
    "-   **Scalable Content Processing:**\n",
    "    \n",
    "    -   This functionality is valuable in scenarios where there is a need to process and summarize large volumes of textual information efficiently.\n",
    "\n",
    "> ### Note\n",
    ">\n",
    "> -   Developers can experiment with different prompts, text lengths, and temperature settings to fine-tune the summarization process based on their specific use case requirements.\n",
    ">     \n",
    "> -   This code snippet illustrates how Claude can be leveraged for content summarization, offering a glimpse into its capabilities in handling natural language understanding and generation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988edc7-b4c8-47aa-a9ad-b9fdc7268235",
   "metadata": {},
   "source": [
    "### Chinese Text Summarization\n",
    "\n",
    "The provided code snippet focuses on leveraging Claude to generate a brief summary of a Chinese text. The text in question describes the characteristics of a neutron star, including its mass, size, and the process by which it is formed. The goal is to obtain a concise summary represented in simplified Chinese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e5c1b8b-ad07-4e17-af99-65c01baf6bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 中子星概述\n",
      "\n",
      "中子星是超级巨星坍缩核心形成的天体，具有以下特点：\n",
      "- 源自质量为10-25太阳质量的超级巨星\n",
      "- 是除黑洞等之外最小最密集的恒星物体\n",
      "- 半径约10公里，质量约1.4太阳质量\n",
      "- 由超新星爆炸和引力坍缩形成，密度达到原子核密度级别\n",
      "\n",
      "--- English Translation ---\n",
      "# Neutron Star Overview\n",
      "\n",
      "Neutron stars are celestial bodies formed from the collapsed cores of supergiant stars, with the following characteristics:\n",
      "- Originate from supergiants with masses of 10-25 solar masses\n",
      "- Are the smallest and densest stellar objects except for black holes and other theoretical objects\n",
      "- Have a radius of approximately 10 kilometers and a mass of about 1.4 solar masses\n",
      "- Formed through supernova explosions and gravitational collapse, reaching nuclear density levels\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"简要概括下面文字：\n",
    "\n",
    "            ###\n",
    "            中子星是一颗质量达10至25太阳质量（如果恒星特别富含金属可能更多）的超级巨星的坍缩核心。\n",
    "            中子星是最小最密集的恒星物体，除了黑洞和假想的白洞、夸克星和奇异星。\n",
    "            中子星的半径约为10公里（6.2英里），质量约为1.4太阳质量。\n",
    "            它们是由超级新星爆炸和引力坍缩共同产生的，使核心压缩到白矮星密度以上的原子核密度。\n",
    "            ###\n",
    "\n",
    "\n",
    "         \"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=800,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)\n",
    "\n",
    "# If you want to convert to English, you can add a follow-up message\n",
    "print(\"\\n--- English Translation ---\")\n",
    "response_english = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=800,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": output_text},\n",
    "        {\"role\": \"user\", \"content\": \"Now translate your summary to English.\"}\n",
    "    ]\n",
    ")\n",
    "print(response_english.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b37557-9e52-494b-b4eb-968f478fd1ad",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "1.  **Prompt Definition:**\n",
    "    \n",
    "    -   The variable `prompt` contains a Chinese passage instructing the model to summarize the provided text.\n",
    "2.  **API Call:**\n",
    "    \n",
    "    -   The `client.messages.create` function is used to send a request to the Claude API.\n",
    "    -   The `model` parameter specifies the Claude model to be used.\n",
    "    -   The `messages` parameter provides the input text (description of a neutron star in Chinese) to the model.\n",
    "    -   The `temperature` parameter is set to 0, indicating that the model's output should be deterministic and focused.\n",
    "    -   The `max_tokens` parameter limits the length of the generated text to 800 tokens.\n",
    "3.  **Response Handling:**\n",
    "    \n",
    "    -   The API response, including the generated summary text, is stored in the `response` variable.\n",
    "4.  **Output Printing:**\n",
    "    \n",
    "    -   The generated summary text is extracted from the API response using `response.content[0].text`.\n",
    "    -   The final result is printed to the console.\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "-   **Cross-Language Summarization:**\n",
    "    \n",
    "    -   This code exemplifies Claude's capability to summarize information in a language other than English, showcasing its multilingual text processing capabilities.\n",
    "-   **Automated Content Summarization:**\n",
    "    \n",
    "    -   It illustrates how the model can be used to automate the process of summarizing content in Chinese, providing a concise overview of a given text.\n",
    "-   **Language Understanding and Generation:**\n",
    "    \n",
    "    -   The code demonstrates the model's proficiency in understanding and generating text in a non-English language, extending its utility to a global context.\n",
    "\n",
    "#### Note\n",
    "\n",
    "-   Developers can adapt this code for various applications, such as building multilingual summarization tools or integrating cross-language capabilities into their natural language processing workflows.\n",
    "    \n",
    "-   Adjustments to the prompt, temperature, and other parameters can be made based on specific use case requirements and language nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814896f",
   "metadata": {},
   "source": [
    "### 3. Classify Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f567f-ac44-4cec-bbdb-585522b770d8",
   "metadata": {},
   "source": [
    "`Classify Text` refers to the task of assigning predefined categories or labels to a given piece of text based on its content and context. The goal is to automatically categorize the text into one or more predefined classes, making it easier to organize, search, and analyze large volumes of textual data. This task falls under the broader field of natural language processing (NLP) and is commonly used in various applications, including sentiment analysis, topic categorization, and content filtering.\n",
    "\n",
    "The process typically involves training a machine learning model on a labeled dataset where each text sample is associated with its corresponding category. The model learns patterns and features from the training data, allowing it to generalize and classify new, unseen text accurately.\n",
    "\n",
    "In the context of the provided code snippet, \"Classify Text\" specifically refers to instructing Claude to categorize a news article into one of the specified categories: Tech, Politics, Sport, or Entertainment. The model generates a response that represents its prediction of the most suitable category based on its understanding of the given news article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd125e-407b-4d97-bd92-e4e8dc3d4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Classify the following news article into 1 of the following categories:\n",
    "            [Tech, Politics, Sport, Entertainment]\n",
    "\n",
    "            ###\n",
    "            Donna Steffensen Is Cooking Up a New Kind of Perfection.\n",
    "            The Internet's most beloved cooking guru has a buzzy new book and\n",
    "            a fresh new perspective: Entertainment\n",
    "\n",
    "            Donna Steffensen Is Cooking Up a New Kind of Perfection.\n",
    "            The Internet's most beloved cooking guru has a buzzy new book and\n",
    "            a fresh new perspective: Politics\n",
    "\n",
    "            Maya's heart pounded as the final buzzer blared.\n",
    "            Sweat stung her eyes, but a smile stretched across her face.\n",
    "            The scoreboard confirmed it: victory by one point.\n",
    "            Exhausted but elated, Maya high-fived her teammates,\n",
    "            the cheers of the crowd a sweet reward.:\n",
    "\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6109264-5d7f-4e93-acb8-365e4852e38e",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "1.  **Prompt Definition:**\n",
    "    \n",
    "    -   The `prompt` variable sets the instructions for the model. It instructs the model to classify the provided news article into one of the predefined categories: Tech, Politics, Sport, or Entertainment.\n",
    "2.  **News Article:**\n",
    "    \n",
    "    -   The provided news article is about Donna Steffensen, described as a cooking guru with a new book and a fresh perspective.\n",
    "3.  **API Call:**\n",
    "    \n",
    "    -   The `client.messages.create` function sends a request to the Claude API for text generation.\n",
    "    -   The `model` parameter specifies the Claude model to be used.\n",
    "    -   The `messages` parameter supplies the input text (news article and classification instruction) to the model.\n",
    "    -   The `temperature` parameter is set to 0.7 for balanced creativity.\n",
    "    -   The `max_tokens` parameter limits the length of the generated text to 800 tokens.\n",
    "4.  **Response Handling:**\n",
    "    \n",
    "    -   The API response, including the generated text (classification result), is stored in the `response` variable.\n",
    "5.  **Output Printing:**\n",
    "    \n",
    "    -   The generated classification result is extracted from the API response using `response.content[0].text`.\n",
    "    -   The final result is printed to the console.\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "-   **Text Classification:**\n",
    "    \n",
    "    -   The code demonstrates the use of Claude for text classification. The model categorizes a given news article into one of the specified classes (Tech, Politics, Sport, or Entertainment).\n",
    "-   **Automated Categorization:**\n",
    "    \n",
    "    -   It showcases the potential for automating the categorization of news articles based on their content, providing a quick and efficient way to organize information.\n",
    "-   **Understanding Context:**\n",
    "    \n",
    "    -   The model's ability to comprehend the context of the news article and assign it to a relevant category highlights its proficiency in understanding natural language and context.\n",
    "\n",
    "#### Note\n",
    "\n",
    "-   Developers can customize the prompt and categories based on their specific use case, expanding the application to various domains that involve text classification.\n",
    "    \n",
    "-   Fine-tuning the parameters, such as temperature, can be explored to influence the randomness and creativity of the generated classification result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127f95b",
   "metadata": {},
   "source": [
    "### 4. Generate New Product Name\n",
    "\n",
    "Automatically create a unique product name based on specified information. With a product description of a \"home milkshake maker\" and seed words like \"fast, healthy, compact,\" the model generates a fitting name inspired by provided examples. This showcases the capability of the model in creative product naming, offering a streamlined and automated approach for inventing distinctive names for various products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68e7324a-e559-42f6-90ce-58f98a92a8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# New Product Name Ideas for Home Milkshake Maker\n",
      "\n",
      "Based on the product description, seed words (fast, healthy, compact), and existing product names, here are some fresh name options:\n",
      "\n",
      "1. **SpeedBlend**\n",
      "2. **NutriShake**\n",
      "3. **SlimMix**\n",
      "4. **VitalWhip**\n",
      "5. **TurboShake**\n",
      "6. **CompactBlitz**\n",
      "7. **QuickHealth**\n",
      "8. **FitMixer**\n",
      "9. **ExpressBlend**\n",
      "10. **TrimShake**\n",
      "11. **SwiftWhirl**\n",
      "12. **HealthDash**\n",
      "13. **MiniMix**\n",
      "14. **RapidBlend**\n",
      "15. **SmartShake**\n",
      "\n",
      "These names incorporate concepts of speed, health benefits, and the compact nature of the product while maintaining a distinctive, marketable quality.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Generate new product name based on the following information：\n",
    "\n",
    "            ###\n",
    "            Product description: A home milkshake maker\n",
    "            Seed words: fast, healthy, compact\n",
    "            Product names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40e666",
   "metadata": {},
   "source": [
    "### 5. Translation\n",
    "\n",
    "In \"Translation\" you translate a Chinese poem into English. The provided poem describes the scenery of mountains, the flow of the Yellow River into the sea, and the desire to explore distant landscapes. The model generates an English translation, showcasing its ability to understand and convert text between different languages. The resulting translation is then printed to the console, demonstrating the model's proficiency in cross-language tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df4f0220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Translation of Wang Zhihuan's \"Climbing Stork Tower\"\n",
      "\n",
      "The sun sets behind the mountains,\n",
      "The Yellow River flows into the sea.\n",
      "To see a thousand miles further,\n",
      "Climb one more floor higher.\n",
      "\n",
      "This classic Tang dynasty poem captures the idea that gaining a better perspective requires making an extra effort to rise above one's current position.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"请用英语翻译下面这首诗歌：\n",
    "\n",
    "            ###\n",
    "            白日依山尽，黄河入海流。\n",
    "            欲穷千里目，更上一层楼。\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783da05",
   "metadata": {},
   "source": [
    "### 6. Parse Unstructured Data\n",
    "\n",
    "In \"Parse Unstructured Data\" you process information about fruits on the fictional planet Goocrux. Descriptions of various fruits, such as neoskizzles, loheckles, pounits, loopnovas, and glowls, are provided. The code instructs the model to create a structured table summarizing these fruits, including details like color and flavor. The resulting table is generated by the model and printed to the console, showcasing the model's ability to organize and present information in a tabular format based on unstructured input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d38ed82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a JSON summarizing the fruits from Goocrux:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"Fruit\": \"Neoskizzle\",\n",
      "    \"Color\": \"Purple\",\n",
      "    \"Flavor\": \"Sweet like candy\"\n",
      "  },\n",
      "  {\n",
      "    \"Fruit\": \"Loheckle\",\n",
      "    \"Color\": \"Grayish blue\",\n",
      "    \"Flavor\": \"Very tart, similar to lemon\"\n",
      "  },\n",
      "  {\n",
      "    \"Fruit\": \"Pounit\",\n",
      "    \"Color\": \"Bright green\",\n",
      "    \"Flavor\": \"More savory than sweet\"\n",
      "  },\n",
      "  {\n",
      "    \"Fruit\": \"Loopnova\",\n",
      "    \"Color\": \"Neon pink\",\n",
      "    \"Flavor\": \"Sweet like cotton candy\"\n",
      "  },\n",
      "  {\n",
      "    \"Fruit\": \"Glowl\",\n",
      "    \"Color\": \"Pale orange\",\n",
      "    \"Flavor\": \"Sour, bitter, acidic and caustic\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"There are many fruits that were found on the recently discovered planet Goocrux.\n",
    "            There are neoskizzles that grow there, which are purple and taste like candy.\n",
    "            There are also loheckles, which are a grayish blue fruit and are very tart, a\n",
    "            little bit like a lemon. Pounits are a bright green color and are more savory\n",
    "            than sweet. There are also plenty of loopnovas which are a neon pink flavor and\n",
    "            taste like cotton candy. Finally, there are fruits called glowls, which have a very\n",
    "            sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\n",
    "\n",
    "            ###\n",
    "            Please make a json summarizing the fruits from Goocrux\n",
    "            { \"Fruit\":\n",
    "              \"Color\":\n",
    "              \"Flavor\":}\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b8a78",
   "metadata": {},
   "source": [
    "### 7. NLP to SQL\n",
    "\n",
    "In \"NLP to SQL\" you convert natural language instructions into a SQL query. The provided prompt defines three PostgreSQL tables (Employee, Department, and Salary_Payments) with their respective properties. The code then instructs the model to generate a SQL query for listing the names of departments that employed more than 10 employees in the last 3 months.\n",
    "\n",
    "The resulting SQL query is generated by the model and printed to the console, showcasing the model's ability to understand and convert natural language queries into structured SQL statements for database operations. This code provides an example of how natural language processing can be applied to automate the generation of SQL queries based on human-readable instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80feffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT d.name\n",
      "FROM Department d\n",
      "JOIN Employee e ON d.id = e.department_id\n",
      "JOIN Salary_Payments sp ON e.id = sp.employee_id\n",
      "WHERE sp.date >= CURRENT_DATE - INTERVAL '3 months'\n",
      "GROUP BY d.id, d.name\n",
      "HAVING COUNT(DISTINCT e.id) > 10\n",
      "```\n",
      "\n",
      "This query:\n",
      "1. Joins the Department, Employee, and Salary_Payments tables\n",
      "2. Filters for salary payments made in the last 3 months\n",
      "3. Groups by department\n",
      "4. Counts distinct employees in each department\n",
      "5. Returns only departments with more than 10 employees who received salary payments in that period\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"### Postgres SQL tables, with their properties:\n",
    "            #\n",
    "            # Employee(id, name, department_id)\n",
    "            # Department(id, name, address)\n",
    "            # Salary_Payments(id, employee_id, amount, date)\n",
    "            #\n",
    "\n",
    "            ### A query to list the names of the departments\n",
    "                which employed more than 10 employees in the last 3 months\n",
    "            ###\n",
    "         \"\"\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_text = response.content[0].text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated various prompt engineering techniques using Claude:\n",
    "\n",
    "1. **Question & Answer** - Basic conversational capabilities\n",
    "2. **Text Summarization** - Condensing long texts into concise summaries\n",
    "3. **Text Classification** - Categorizing content into predefined classes\n",
    "4. **Creative Generation** - Generating product names and creative content\n",
    "5. **Translation** - Multilingual capabilities including Chinese to English\n",
    "6. **Data Parsing** - Converting unstructured text into structured formats (JSON)\n",
    "7. **NLP to SQL** - Translating natural language into database queries\n",
    "\n",
    "Claude excels at all these tasks and offers several advantages:\n",
    "- Strong instruction following\n",
    "- Excellent multilingual support\n",
    "- Large context windows (200K tokens)\n",
    "- Reliable structured output generation\n",
    "- Thoughtful and detailed responses\n",
    "\n",
    "Feel free to experiment with different prompts, temperatures, and max_tokens values to explore Claude's capabilities further!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-workshop",
   "language": "python",
   "name": "genai-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
