{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Google Gemini\n",
    "\n",
    "This notebook demonstrates how to build a simple chatbot using Google's Gemini API.\n",
    "\n",
    "**Free Tier:** No credit card required - just a Google account!\n",
    "\n",
    "We'll create a sourdough bread expert assistant that can answer questions about baking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.6-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: python-dotenv in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Using cached google_api_core-2.29.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Using cached google_api_python_client-2.188.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Using cached google_auth-2.47.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: protobuf in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.15.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached proto_plus-1.27.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.31.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.3.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Using cached uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio-1.76.0-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Using cached protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Using cached google_generativeai-0.8.6-py3-none-any.whl (155 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Using cached google_api_core-2.29.0-py3-none-any.whl (173 kB)\n",
      "Using cached google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
      "Downloading google_api_python_client-2.188.0-py3-none-any.whl (14.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:02\u001b[0mm\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.3.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading httplib2-0.31.1-py3-none-any.whl (91 kB)\n",
      "Downloading proto_plus-1.27.0-py3-none-any.whl (50 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.29.0 google-api-python-client-2.188.0 google-auth-2.47.0 google-auth-httplib2-0.3.0 google-generativeai-0.8.6 googleapis-common-protos-1.72.0 grpcio-1.76.0 grpcio-status-1.71.2 httplib2-0.31.1 proto-plus-1.27.0 protobuf-5.29.5 rsa-4.9.1 uritemplate-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get Your API Key\n",
    "\n",
    "1. Go to [Google AI Studio](https://aistudio.google.com/)\n",
    "2. Sign in with your Google account\n",
    "3. Click **\"Get API Key\"** → **\"Create API key\"**\n",
    "4. Copy the key and add it to your `.env` file:\n",
    "\n",
    "```\n",
    "GOOGLE_API_KEY=your-api-key-here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gemini-2.0-flash\n",
      "API key configured: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/5tqvpsvd61z199n35_ktybsm0000gn/T/ipykernel_4078/1373392278.py:3: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the Gemini API\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Choose your Gemini model\n",
    "# Options: gemini-2.0-flash (fast), gemini-1.5-pro (more capable), gemini-2.0-flash-lite (newest fast)\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "model = genai.GenerativeModel(model_name)\n",
    "\n",
    "print(f\"Using model: {model_name}\")\n",
    "print(f\"API key configured: {'Yes' if api_key else 'No - please set GOOGLE_API_KEY'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Chatbot Function\n",
    "\n",
    "We'll create a function that sends user input to Gemini and returns the response.\n",
    "The system instruction defines the chatbot's persona as a sourdough bread expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System instruction that defines the chatbot's behavior\n",
    "SYSTEM_INSTRUCTION = \"\"\"You are an expert baker assistant that helps home bakers with questions about their sourdough bread dough. \n",
    "\n",
    "You are knowledgeable about:\n",
    "- Sourdough starters (feeding, maintenance, troubleshooting)\n",
    "- Dough hydration and flour types\n",
    "- Fermentation and proofing\n",
    "- Shaping and scoring techniques\n",
    "- Baking temperatures and timing\n",
    "- Troubleshooting common issues\n",
    "\n",
    "Provide helpful, encouraging advice to home bakers of all skill levels.\"\"\"\n",
    "\n",
    "# Create model with system instruction\n",
    "chatbot_model = genai.GenerativeModel(\n",
    "    model_name,\n",
    "    system_instruction=SYSTEM_INSTRUCTION\n",
    ")\n",
    "\n",
    "def chat_with_bot(user_input):\n",
    "    \"\"\"Send a message to Gemini and get a response.\"\"\"\n",
    "    try:\n",
    "        response = chatbot_model.generate_content(user_input)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversation: {e}\")\n",
    "        return \"Sorry, I couldn't process your request.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test the Chatbot\n",
    "\n",
    "Let's test our chatbot with some sourdough-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during conversation: 404 models/gemini-2.0-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "Question: When is my sourdough starter ready to use?\n",
      "\n",
      "Chatbot Response:\n",
      "Sorry, I couldn't process your request.\n"
     ]
    }
   ],
   "source": [
    "# Test question 1\n",
    "question1 = \"When is my sourdough starter ready to use?\"\n",
    "response1 = chat_with_bot(question1)\n",
    "\n",
    "print(\"Question:\", question1)\n",
    "print(\"\\nChatbot Response:\")\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test question 2\n",
    "question2 = \"My dough is too sticky. What should I do?\"\n",
    "response2 = chat_with_bot(question2)\n",
    "\n",
    "print(\"Question:\", question2)\n",
    "print(\"\\nChatbot Response:\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test question 3\n",
    "question3 = \"What's the ideal temperature for bulk fermentation?\"\n",
    "response3 = chat_with_bot(question3)\n",
    "\n",
    "print(\"Question:\", question3)\n",
    "print(\"\\nChatbot Response:\")\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrating System Instruction Importance\n",
    "\n",
    "Let's see how the system instruction affects responses by asking off-topic questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With system instruction (sourdough expert)\n",
    "print(\"WITH System Instruction (Sourdough Expert):\")\n",
    "print(\"-\" * 40)\n",
    "response_with = chat_with_bot(\"What's the capital of France?\")\n",
    "print(response_with)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Without system instruction (general model)\n",
    "print(\"WITHOUT System Instruction (General):\")\n",
    "print(\"-\" * 40)\n",
    "general_model = genai.GenerativeModel(model_name)\n",
    "response_without = general_model.generate_content(\"What's the capital of France?\")\n",
    "print(response_without.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Interactive Chatbot (Optional)\n",
    "\n",
    "Run the cell below to start an interactive chat session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat loop\n",
    "print(\"Sourdough Expert Chatbot (Gemini)\")\n",
    "print(\"=\" * 35)\n",
    "print(\"Ask me anything about sourdough baking!\")\n",
    "print(\"Type 'exit' or 'quit' to end the conversation.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Goodbye! Happy baking!\")\n",
    "        break\n",
    "    response = chat_with_bot(user_input)\n",
    "    print(f\"\\nChatbot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Chatbot with Conversation History\n",
    "\n",
    "Gemini has built-in chat functionality that maintains conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat session (automatically maintains history)\n",
    "chat = chatbot_model.start_chat(history=[])\n",
    "\n",
    "# First message\n",
    "print(\"User: I'm making sourdough for the first time. Where do I start?\")\n",
    "response = chat.send_message(\"I'm making sourdough for the first time. Where do I start?\")\n",
    "print(f\"\\nChatbot: {response.text}\\n\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Follow-up question (chat remembers context)\n",
    "print(\"User: How long does that take?\")\n",
    "response = chat.send_message(\"How long does that take?\")\n",
    "print(f\"\\nChatbot: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "\n",
    "1. **Set up the Google Gemini API** - Install the SDK and configure authentication\n",
    "2. **Create a simple chatbot** - Send user messages and receive AI responses\n",
    "3. **Use system instructions** - Define the chatbot's persona and behavior\n",
    "4. **Maintain conversation history** - Use Gemini's built-in chat functionality\n",
    "\n",
    "### API Comparison:\n",
    "\n",
    "| Feature | OpenAI | Claude | Gemini |\n",
    "|---------|--------|--------|--------|\n",
    "| Client setup | `openai.ChatCompletion.create()` | `client.messages.create()` | `model.generate_content()` |\n",
    "| System message | In messages array | Separate `system` param | `system_instruction` in model |\n",
    "| Response | `response.choices[0].message['content']` | `response.content[0].text` | `response.text` |\n",
    "| Chat history | Manual | Manual | Built-in `start_chat()` |\n",
    "| Free tier | No | No | **Yes!** |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-workshop",
   "language": "python",
   "name": "genai-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
