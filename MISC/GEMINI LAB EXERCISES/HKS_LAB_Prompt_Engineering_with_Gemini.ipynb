{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HKS LAB: Prompt Engineering with Google Gemini\n",
    "\n",
    "This notebook explores various prompt engineering techniques using Google's Gemini API.\n",
    "\n",
    "**Free Tier:** No credit card required - just a Google account!\n",
    "\n",
    "## Scenarios Covered:\n",
    "1. QnA (Question Answering)\n",
    "2. Text Summarization\n",
    "3. Multilingual Summarization\n",
    "4. Text Classification\n",
    "5. Creative Generation\n",
    "6. Translation\n",
    "7. Parsing Unstructured Data\n",
    "8. NLP to SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "print(f\"API key configured: {'Yes' if api_key else 'No - please set GOOGLE_API_KEY'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gemini(prompt, temperature=0.7, max_tokens=150):\n",
    "    \"\"\"Send a prompt to Gemini and return the response.\"\"\"\n",
    "    config = genai.GenerationConfig(\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_tokens\n",
    "    )\n",
    "    response = model.generate_content(prompt, generation_config=config)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario 1: QnA (Question Answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Who are you?\"\n",
    "\n",
    "response = query_gemini(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QnA with specific format request\n",
    "prompt = \"\"\"What are the planets of the solar system? \n",
    "List them in order from the sun in YAML format.\"\"\"\n",
    "\n",
    "response = query_gemini(prompt, max_tokens=300)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QnA in a different language\n",
    "prompt = \"What are the planets in solar system? Answer in French.\"\n",
    "\n",
    "response = query_gemini(prompt, max_tokens=300)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario 2: Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Summarize the following text in 2-3 sentences:\n",
    "\n",
    "A neutron star is the collapsed core of a massive supergiant star, which had a total \n",
    "mass of between 10 and 25 solar masses, possibly more if the star was especially \n",
    "metal-rich. Neutron stars are the smallest and densest stellar objects, excluding \n",
    "black holes and hypothetical white holes, quark stars, and strange stars. Neutron \n",
    "stars have a radius on the order of 10 kilometres (6.2 mi) and a mass of about 1.4 \n",
    "solar masses. They result from the supernova explosion of a massive star, combined \n",
    "with gravitational collapse, that compresses the core past white dwarf star density \n",
    "to that of atomic nuclei.\n",
    "\"\"\"\n",
    "\n",
    "response = query_gemini(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario 3: Multilingual Summarization (Chinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Summarize the following Chinese text, then translate the summary to English:\n",
    "\n",
    "产品信息: 2023年新款智能手表发布，搭载高通骁龙芯片，支持4G通话功能，续航时间长达72小时。\n",
    "该手表采用1.5英寸AMOLED屏幕，分辨率为466x466像素。支持心率监测、血氧检测、睡眠追踪等健康功能。\n",
    "防水等级达到5ATM，适合游泳佩戴。售价2999元人民币。\n",
    "\"\"\"\n",
    "\n",
    "response = query_gemini(prompt, max_tokens=300)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario 4: Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Classify each news headline into one of these categories: \n",
    "Sports, Technology, Politics, Entertainment, Business\n",
    "\n",
    "Headlines:\n",
    "1. \"Apple announces new iPhone with revolutionary AI features\"\n",
    "2. \"Lakers defeat Warriors in overtime thriller\"\n",
    "3. \"Senate passes new infrastructure bill\"\n",
    "4. \"Netflix stock surges after subscriber growth\"\n",
    "5. \"Taylor Swift breaks streaming records with new album\"\n",
    "\n",
    "Format: Headline number - Category\n",
    "\"\"\"\n",
    "\n",
    "response = query_gemini(prompt, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario 5: Creative Generation (Product Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Generate 5 creative product names for a new eco-friendly water bottle \n",
    "that keeps drinks cold for 24 hours and hot for 12 hours.\n",
    "\n",
    "The names should be:\n",
    "- Memorable and catchy\n",
    "- Suggest sustainability\n",
    "- Appeal to young professionals\n",
    "\"\"\"\n",
    "\n",
    "response = query_gemini(prompt, temperature=0.9, max_tokens=200)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario 6: Translation (Chinese Poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Translate this famous Chinese poem to English, maintaining the poetic structure:\n",
    "\n",
    "静夜思 - 李白\n",
    "床前明月光，\n",
    "疑是地上霜。\n",
    "举头望明月，\n",
    "低头思故乡。\n",
    "\n",
    "Also provide a brief explanation of the poem's meaning and cultural significance.\n",
    "\"\"\"\n",
    "\n",
    "response = query_gemini(prompt, max_tokens=400)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario 7: Parsing Unstructured Data to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Extract the product information from this text and format it as JSON:\n",
    "\n",
    "\"We have Goocrux fruits available. They're purple and cost $5.20 per pound. \n",
    "We also have Blotfruit which is green and costs $3.50 per pound. \n",
    "Finally, there's Snozzberry - it's red and the most expensive at $8.99 per pound.\"\n",
    "\n",
    "Output format:\n",
    "{\n",
    "  \"products\": [\n",
    "    {\"name\": \"...\", \"color\": \"...\", \"price_per_pound\": ...}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = query_gemini(prompt, temperature=0, max_tokens=300)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scenario 8: NLP to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Convert this natural language query to SQL:\n",
    "\n",
    "Database schema:\n",
    "- employees (id, name, department, salary, hire_date)\n",
    "- departments (id, name, budget)\n",
    "\n",
    "Query: \"Show me the names and salaries of all employees in the Engineering \n",
    "department who earn more than $100,000, ordered by salary from highest to lowest\"\n",
    "\n",
    "Return only the SQL query.\n",
    "\"\"\"\n",
    "\n",
    "response = query_gemini(prompt, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another NLP to SQL example\n",
    "prompt = \"\"\"\n",
    "Convert this natural language query to SQL:\n",
    "\n",
    "Database schema:\n",
    "- orders (id, customer_id, product_id, quantity, order_date, total_amount)\n",
    "- customers (id, name, email, city)\n",
    "- products (id, name, category, price)\n",
    "\n",
    "Query: \"What are the top 5 customers by total spending in 2024, \n",
    "showing their name, email, and total amount spent?\"\n",
    "\n",
    "Return only the SQL query.\n",
    "\"\"\"\n",
    "\n",
    "response = query_gemini(prompt, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated 8 different prompt engineering scenarios:\n",
    "\n",
    "| Scenario | Technique | Temperature |\n",
    "|----------|-----------|-------------|\n",
    "| QnA | Direct questioning | 0.7 |\n",
    "| Summarization | Instruction-based | 0.7 |\n",
    "| Multilingual | Multi-step instructions | 0.7 |\n",
    "| Classification | Zero-shot classification | 0 |\n",
    "| Creative | High creativity generation | 0.9 |\n",
    "| Translation | Preserve structure | 0.7 |\n",
    "| Data Parsing | Structured output | 0 |\n",
    "| NLP to SQL | Code generation | 0 |\n",
    "\n",
    "### Key Takeaways:\n",
    "- Use **low temperature (0)** for factual/structured tasks\n",
    "- Use **high temperature (0.9)** for creative tasks\n",
    "- Be **specific** about output format\n",
    "- Provide **examples** when needed (few-shot)\n",
    "- Gemini's **free tier** makes it great for learning and workshops!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
