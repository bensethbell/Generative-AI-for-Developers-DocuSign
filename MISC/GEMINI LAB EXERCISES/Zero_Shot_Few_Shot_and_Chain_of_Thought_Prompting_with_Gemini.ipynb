{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot, Few-Shot, and Chain-of-Thought Prompting with Gemini\n",
    "\n",
    "This notebook demonstrates three fundamental prompting techniques using Google's Gemini API:\n",
    "\n",
    "1. **Zero-Shot Prompting** - Ask the model to perform a task without any examples\n",
    "2. **Few-Shot Prompting** - Provide a few examples to guide the model's responses\n",
    "3. **Chain-of-Thought Prompting** - Ask the model to show its reasoning step by step\n",
    "\n",
    "**Free Tier:** No credit card required - just a Google account!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up the Gemini Client\n",
    "\n",
    "Get your free API key at [Google AI Studio](https://aistudio.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the Gemini API\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Choose your Gemini model\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "model = genai.GenerativeModel(model_name)\n",
    "\n",
    "print(f\"Using model: {model_name}\")\n",
    "print(f\"API key configured: {'Yes' if api_key else 'No - please set GOOGLE_API_KEY'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gemini(prompt, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Send a prompt to Gemini and return the response.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The user's prompt/question\n",
    "        temperature: Controls randomness (0=focused, 1=creative)\n",
    "    \n",
    "    Returns:\n",
    "        The model's response text\n",
    "    \"\"\"\n",
    "    generation_config = genai.GenerationConfig(\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=500\n",
    "    )\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Technique 1: Zero-Shot Prompting\n",
    "\n",
    "**Zero-shot prompting** means asking the model to perform a task without providing any examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Prompting Example 1: General knowledge\n",
    "zero_shot_prompt = \"What are the benefits of regular exercise?\"\n",
    "\n",
    "zero_shot_response = query_gemini(zero_shot_prompt)\n",
    "\n",
    "print(\"ZERO-SHOT PROMPTING\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Prompt: {zero_shot_prompt}\")\n",
    "print(f\"\\nResponse:\\n{zero_shot_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Prompting Example 2: Sentiment Analysis\n",
    "zero_shot_sentiment = \"\"\"Classify the sentiment of this review as positive, negative, or neutral:\n",
    "\n",
    "\"The restaurant had amazing food but the service was incredibly slow. I'm not sure if I'd go back.\"\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "response = query_gemini(zero_shot_sentiment, temperature=0)\n",
    "\n",
    "print(\"ZERO-SHOT SENTIMENT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Prompt: {zero_shot_sentiment}\")\n",
    "print(f\"\\nResponse: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Technique 2: Few-Shot Prompting\n",
    "\n",
    "**Few-shot prompting** provides the model with a few examples of the desired input-output pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-Shot Prompting Example 1: Translation\n",
    "few_shot_translation = \"\"\"Translate the following English sentences to French:\n",
    "\n",
    "1. Hello. -> Bonjour.\n",
    "2. How are you? -> Comment Ã§a va?\n",
    "3. What is your name? ->\"\"\"\n",
    "\n",
    "few_shot_response = query_gemini(few_shot_translation)\n",
    "\n",
    "print(\"FEW-SHOT PROMPTING: Translation\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Prompt: {few_shot_translation}\")\n",
    "print(f\"\\nResponse: {few_shot_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-Shot Prompting Example 2: Custom Classification\n",
    "few_shot_classification = \"\"\"Classify these customer support tickets into categories.\n",
    "\n",
    "Ticket: \"I can't log into my account\"\n",
    "Category: Account Access\n",
    "\n",
    "Ticket: \"When will my order arrive?\"\n",
    "Category: Shipping\n",
    "\n",
    "Ticket: \"I want a refund for my purchase\"\n",
    "Category: Returns/Refunds\n",
    "\n",
    "Ticket: \"The app keeps crashing on my phone\"\n",
    "Category:\"\"\"\n",
    "\n",
    "response = query_gemini(few_shot_classification, temperature=0)\n",
    "\n",
    "print(\"FEW-SHOT PROMPTING: Classification\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Prompt: {few_shot_classification}\")\n",
    "print(f\"\\nResponse: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-Shot Prompting Example 3: Structured Output\n",
    "few_shot_structured = \"\"\"Extract information from text and format as JSON.\n",
    "\n",
    "Text: \"John Smith is 35 years old and works as a software engineer.\"\n",
    "JSON: {\"name\": \"John Smith\", \"age\": 35, \"occupation\": \"software engineer\"}\n",
    "\n",
    "Text: \"Maria Garcia, a 28-year-old doctor, lives in Boston.\"\n",
    "JSON: {\"name\": \"Maria Garcia\", \"age\": 28, \"occupation\": \"doctor\", \"city\": \"Boston\"}\n",
    "\n",
    "Text: \"The CEO, Robert Chen, announced the merger at age 52.\"\n",
    "JSON:\"\"\"\n",
    "\n",
    "response = query_gemini(few_shot_structured, temperature=0)\n",
    "\n",
    "print(\"FEW-SHOT PROMPTING: Structured Output\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Prompt: {few_shot_structured}\")\n",
    "print(f\"\\nResponse: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Technique 3: Chain-of-Thought Prompting\n",
    "\n",
    "**Chain-of-Thought (CoT) prompting** asks the model to break down its reasoning into steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-Thought Example 1: Simple Math\n",
    "cot_simple = \"\"\"Calculate the following: If I have 3 apples and I buy 2 more, \n",
    "how many apples do I have in total? Please show your work step by step.\"\"\"\n",
    "\n",
    "cot_response = query_gemini(cot_simple)\n",
    "\n",
    "print(\"CHAIN-OF-THOUGHT: Simple Math\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Prompt: {cot_simple}\")\n",
    "print(f\"\\nResponse:\\n{cot_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-Thought Example 2: Multi-step Word Problem\n",
    "cot_complex = \"\"\"Solve this problem step by step:\n",
    "\n",
    "A store sells notebooks for $3 each and pens for $1.50 each. \n",
    "Sarah has $20 and wants to buy 4 notebooks. \n",
    "How many pens can she buy with the remaining money?\n",
    "\n",
    "Think through this step by step:\"\"\"\n",
    "\n",
    "response = query_gemini(cot_complex)\n",
    "\n",
    "print(\"CHAIN-OF-THOUGHT: Word Problem\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Prompt: {cot_complex}\")\n",
    "print(f\"\\nResponse:\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-Thought Example 3: Logic Puzzle\n",
    "cot_logic = \"\"\"Solve this logic puzzle step by step:\n",
    "\n",
    "Three friends - Alice, Bob, and Carol - each have a different pet: a cat, a dog, or a fish.\n",
    "- Alice doesn't have the cat.\n",
    "- Bob doesn't have the dog.\n",
    "- Carol doesn't have the cat or the fish.\n",
    "\n",
    "Who has which pet? Show your reasoning.\"\"\"\n",
    "\n",
    "response = query_gemini(cot_logic)\n",
    "\n",
    "print(\"CHAIN-OF-THOUGHT: Logic Puzzle\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Prompt: {cot_logic}\")\n",
    "print(f\"\\nResponse:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparison: Same Task, Different Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The task: Determine if a number is prime\n",
    "number = 97\n",
    "\n",
    "# Zero-shot\n",
    "zero_shot = f\"Is {number} a prime number? Answer yes or no.\"\n",
    "\n",
    "# Few-shot\n",
    "few_shot = f\"\"\"Determine if a number is prime:\n",
    "Number: 7 -> Prime: Yes\n",
    "Number: 12 -> Prime: No\n",
    "Number: 23 -> Prime: Yes\n",
    "Number: {number} -> Prime:\"\"\"\n",
    "\n",
    "# Chain-of-thought\n",
    "cot = f\"\"\"Is {number} a prime number? \n",
    "Think step by step: check if it's divisible by small prime numbers (2, 3, 5, 7, etc.).\n",
    "Show your work and then give the final answer.\"\"\"\n",
    "\n",
    "print(\"COMPARISON: Is 97 prime?\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n--- Zero-Shot ---\")\n",
    "print(query_gemini(zero_shot, temperature=0))\n",
    "\n",
    "print(\"\\n--- Few-Shot ---\")\n",
    "print(query_gemini(few_shot, temperature=0))\n",
    "\n",
    "print(\"\\n--- Chain-of-Thought ---\")\n",
    "print(query_gemini(cot, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Technique | Description | Best For |\n",
    "|-----------|-------------|----------|\n",
    "| **Zero-Shot** | No examples provided | Simple tasks, quick queries |\n",
    "| **Few-Shot** | 2-5 examples provided | Custom formats, classification |\n",
    "| **Chain-of-Thought** | Ask for step-by-step reasoning | Math, logic, complex problems |\n",
    "\n",
    "### API Comparison:\n",
    "\n",
    "| Feature | OpenAI | Claude | Gemini |\n",
    "|---------|--------|--------|--------|\n",
    "| Basic call | `ChatCompletion.create()` | `messages.create()` | `generate_content()` |\n",
    "| Response | `choices[0].message['content']` | `content[0].text` | `response.text` |\n",
    "| Temperature | In params | In params | In `GenerationConfig` |\n",
    "| Free tier | No | No | **Yes!** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Try Your Own Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! Try different prompts here\n",
    "my_prompt = \"\"\"Your prompt here...\"\"\"\n",
    "\n",
    "response = query_gemini(my_prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
