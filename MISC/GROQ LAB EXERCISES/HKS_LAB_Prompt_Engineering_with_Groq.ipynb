{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HKS LAB: Prompt Engineering with Groq\n",
    "\n",
    "**Free Tier:** 14,400 requests/day, no credit card!\n",
    "\n",
    "## Scenarios:\n",
    "1. QnA\n",
    "2. Summarization\n",
    "3. Multilingual\n",
    "4. Classification\n",
    "5. Creative Generation\n",
    "6. Translation\n",
    "7. Data Parsing\n",
    "8. NLP to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from groq) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mannasethsotsky/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "prompt = \"Who are you?\"\n",
    "\n",
    "load_dotenv()\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "model = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "def query(prompt, temp=0.7, max_tokens=300):\n",
    "    r = client.chat.completions.create(\n",
    "        model=model, temperature=temp, max_tokens=max_tokens,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return r.choices[0].message.content\n",
    "\n",
    "print(query(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "print(query(\"Who are you?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a list of the 8 planets in our solar system, in order, in YAML format:\n",
      "\n",
      "```yml\n",
      "planets:\n",
      "  - Mercury\n",
      "  - Venus\n",
      "  - Earth\n",
      "  - Mars\n",
      "  - Jupiter\n",
      "  - Saturn\n",
      "  - Uranus\n",
      "  - Neptune\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(query(\"List planets in solar system order in YAML format.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les planètes de notre système solaire sont :\n",
      "\n",
      "1. Mercure (la plus proche du soleil)\n",
      "2. Vénus\n",
      "3. Terre (notre planète)\n",
      "4. Mars\n",
      "5. Jupiter (la plus grande planète)\n",
      "6. Saturne\n",
      "7. Uranus\n",
      "8. Neptune (la plus éloignée du soleil)\n",
      "\n",
      "Il y a également des planètes naines, comme Pluton, qui ont été découvertes plus récemment.\n",
      "\n",
      "Note : Il est important de noter que la définition de planète a évolué au fil du temps, et que certaines sources peuvent inclure ou exclure certaines planètes de la liste ci-dessus. Cependant, les huit planètes mentionnées ci-dessus sont généralement reconnues comme les planètes principales de notre système solaire.\n"
     ]
    }
   ],
   "source": [
    "print(query(\"What are the planets? Answer in French.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"A neutron star is the collapsed core of a massive supergiant star. \n",
    "Neutron stars are the smallest and densest stellar objects, excluding black holes. \n",
    "They have a radius of about 10 km and a mass of about 1.4 solar masses.\"\"\"\n",
    "\n",
    "print(query(f\"Summarize in 2 sentences:\\n\\n{text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilingual (Chinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese = \"\"\"产品信息: 2023年新款智能手表，支持4G通话，续航72小时。\n",
    "1.5英寸AMOLED屏幕，支持心率监测、血氧检测。售价2999元。\"\"\"\n",
    "\n",
    "print(query(f\"Summarize this Chinese text, then translate to English:\\n\\n{chinese}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Classify into Sports, Tech, Politics, Entertainment, Business:\n",
    "1. \\\"Apple announces new iPhone with AI features\\\"\n",
    "2. \\\"Lakers defeat Warriors in overtime\\\"\n",
    "3. \\\"Senate passes infrastructure bill\\\"\n",
    "4. \\\"Netflix stock surges\\\"\n",
    "5. \\\"Taylor Swift breaks streaming records\\\"\"\"\"\n",
    "\n",
    "print(query(prompt, temp=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creative Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query(\"Generate 5 creative names for an eco-friendly water bottle.\", temp=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Translation (Chinese Poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = \"\"\"Translate to English with explanation:\n",
    "\n",
    "静夜思 - 李白\n",
    "床前明月光，疑是地上霜。\n",
    "举头望明月，低头思故乡。\"\"\"\n",
    "\n",
    "print(query(poem, max_tokens=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Parsing to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Extract as JSON:\n",
    "\\\"We have Goocrux (purple, $5.20/lb), Blotfruit (green, $3.50/lb), \n",
    "and Snozzberry (red, $8.99/lb).\\\"\n",
    "\n",
    "Format: {\\\"products\\\": [{\\\"name\\\": ..., \\\"color\\\": ..., \\\"price\\\": ...}]}\"\"\"\n",
    "\n",
    "print(query(prompt, temp=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. NLP to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Convert to SQL:\n",
    "Tables: employees(id, name, department, salary), departments(id, name)\n",
    "\n",
    "Query: \\\"Engineering employees earning over $100k, sorted by salary desc\\\"\"\"\"\n",
    "\n",
    "print(query(prompt, temp=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Convert to SQL:\n",
    "Tables: orders(id, customer_id, total_amount, order_date), customers(id, name, email)\n",
    "\n",
    "Query: \\\"Top 5 customers by total spending in 2024 with name, email, total\\\"\"\"\"\n",
    "\n",
    "print(query(prompt, temp=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Scenario | Temperature |\n",
    "|----------|-------------|\n",
    "| QnA | 0.7 |\n",
    "| Classification | 0 |\n",
    "| Creative | 0.9 |\n",
    "| SQL/JSON | 0 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-workshop",
   "language": "python",
   "name": "genai-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
